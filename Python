#!/usr/bin/env python
# coding: utf-8

# In[4]:


# Installs dependencies
import tensorflow as tf
import os
import sys


# In[5]:


# Removes incompatible images 
# Imports dependencies
import cv2
import imghdr

# Creates a variable holding the path to the data directory
data_dir = 'data'

# Creates a list of extensions 
image_exts = ['jpeg', 'jpg', 'bmp', 'png']


# In[6]:


# Loops through every folder in the data directory
for subdir in ['test', 'train', 'validation']:
    for image_class in os.listdir(os.path.join(data_dir, subdir)):
        # Excludes the .DS_Store file
        if image_class == '.DS_Store':
            continue
        # Prints every single image within the sub-directory
        for image in os.listdir(os.path.join(data_dir, subdir, image_class)):
            # Grabs every image
            image_path = os.path.join(data_dir, subdir, image_class, image)
            try:
                # Opens an image using OpenCV
                img = cv2.imread(image_path)
                # Checks if the image is valid
                if imghdr.what(image_path) not in image_exts:
                    # Removes the image if it's not valid
                    os.remove(image_path)
                    print('Image not in exts list: {}'.format(image_path))
            except:
                # Removes the image if it cannot be opened
                os.remove(image_path)
                print('Issue with image: {}'.format(image_path))


# In[7]:


# Imports dependencies
import numpy as np 
from matplotlib import pyplot as plt


# In[8]:


# Builds an image dataset, using keras
test = tf.keras.utils.image_dataset_from_directory('data/test')
train = tf.keras.utils.image_dataset_from_directory('data/train')
val= tf.keras.utils.image_dataset_from_directory('data/validation')


# In[9]:


# Allow us to convert to a numpy iterator, allows access to the image dataset
data_iterator_test = test.as_numpy_iterator()
data_iterator_train = train.as_numpy_iterator()
data_iterator_val = val.as_numpy_iterator()


# In[10]:


# Grabs a batch 
try:
    batch_test = data_iterator_test.next()
    batch_train = data_iterator_train.next()
    batch_val = data_iterator_val.next()
except StopIteration:
    print("End of dataset reached")


# In[12]:


# Checks which class is assigned to which image within the train dataset
fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch_train[0][:4]):
    ax[idx].imshow(img.astype(int))
    ax[idx].title.set_text(batch_train[1][idx])


# In[445]:


# Scales the data
# x represents the images 
# y represents the labels
test = data.map(lambda x,y: (x/255, y))
train = data.map(lambda x,y: (x/255, y))
val = data.map(lambda x,y: (x/255, y))


# In[446]:


# Iterates batches of data as NumPy arrays
# Every iterator returns a single data batch
scaled_iterator_test = test.as_numpy_iterator()
scaled_iterator_train = train.as_numpy_iterator()
scaled_iterator_val = val.as_numpy_iterator() 


# In[452]:


# Scaled iterator
try: 
    batch_test = scaled_iterator_test.next()
    batch_train = scaled_iterator_train.next()
    batch_val = scaled_iterator_val.next()
except StopIteration:
    print("End of dataset reached")


# In[453]:


# Grabs next batch
batch_test[0].max()


# In[454]:


# Checks which class is assigned to which image within the test dataset
# Checks that they've been scaled correctly 
fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch_test[0][:4]):
    ax[idx].imshow(img)
    ax[idx].title.set_text(batch_test[1][idx])


# In[455]:


# Grabs next batch
batch_train[0].max()


# In[456]:


# Checks which class is assigned to which image
# Checks that they've been scaled correctly 
fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch_train[0][:4]):
    ax[idx].imshow(img)
    ax[idx].title.set_text(batch_train[1][idx])


# In[392]:


# Grabs next batch
batch_val[0].max()


# In[393]:


# Checks which class is assigned to which image
# Checks that they've been scaled correctly 
fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch_val[0][:4]):
    ax[idx].imshow(img)
    ax[idx].title.set_text(batch_val[1][idx])


# In[394]:


# Imports dependencies
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout


# In[395]:


# Establishes an instance of the sequential class
model = Sequential()


# In[396]:


# Adds in our layers

# Adds a convolutional layer and a max pooling layer
# Has 16 filters (3,3 pixels in size)
# Stride moving one pixel by one 
# Extracts the relevant information to make a classification
# Applies a relu activation - taking into account non-linear patterns
# Image shape is going to be 256 wide by 256 heigh, 3 channels deeps 
model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))
model.add(MaxPooling2D())

# Adds a convolutional layer and a max pooling layer
# Has 32 filters (3,3 pixels in size)
# Stride moving one pixel by one 
model.add(Conv2D(32, (3,3), 1, activation='relu'))
model.add(MaxPooling2D())

# Adds a convolutional layer and a max pooling layer
# Has 16 filters (3,3 pixels in size)
# Stride moving one pixel by one 
model.add(Conv2D(16, (3,3), 1, activation='relu'))
model.add(MaxPooling2D())

# Flattens to remove the channels value 
model.add(Flatten())

# 256 values will now be the output
model.add(Dense(256, activation='relu'))
# Creates a single output, 0 or 1 
model.add(Dense(1, activation='sigmoid'))


# In[397]:


# Compiles the model using the 'adam' optimiser. Specifying what the loss is. The metric tracked is accuracy, shows how well the model is classifying either 0 or 1.
model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])


# In[398]:


# Displays how the model transforms the data
model.summary()


# In[399]:


# Refers to the logs directory
logdir='logs'


# In[400]:


# Logs model training into the 'logs' file
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)


# In[401]:


# Model.fit takes in the training data
# Epoche is how long we're going to train for
# Passes through the validation data, to see how well the model is performing in real time
# Stores in a variable called history 
hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])


# In[403]:


# Plots the performance 
fig = plt.figure()

# Grabs the training loss
plt.plot(hist.history['loss'], color='teal', label='loss')

# Grabs the validation loss
plt.plot(hist.history['val_loss'], color='orange', label='val_loss')

fig.suptitle('Loss', fontsize=20)
plt.legend(loc="upper left")
plt.show()


# In[404]:


# Plots the performance, visualising accuracy
fig = plt.figure()

plt.plot(hist.history['accuracy'], color='teal', label='accuracy')

plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')
fig.suptitle('Accuracy', fontsize=20)
plt.legend(loc="upper left")
plt.show()


# In[405]:


# Imports key metrics
from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy


# In[406]:


# Establishes instances of the metrics
pre = Precision()
re = Recall()
acc = BinaryAccuracy()


# In[407]:


# Loops through each batch in the testing data
for batch in test.as_numpy_iterator(): 
    X, y = batch
    # Passes image data to our model, returns values of 0 or 1 
    yhat = model.predict(X)
    # Returns precision
    pre.update_state(y, yhat)
    # Returns recall
    re.update_state(y, yhat)
    # Returns accuracy
    acc.update_state(y, yhat)


# In[408]:


print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy: {acc.result().numpy()}')


# In[409]:


# Imports opencv
import cv2


# In[425]:


# Reads and display images
img = cv2.imread('5a2b4bbf-d9fe-45a2-aa0d-295a86804cb6.jpg')
plt.imshow(img)
plt.show()


# In[426]:


# Resizes to 256 wide and 256 heigh
resize = tf.image.resize(img, (256,256))
# Displays the resized image
plt.imshow(resize.numpy().astype(int))
plt.show()


# In[427]:


yhat = model.predict(np.expand_dims(resize/255, 0))


# In[428]:


yhat


# In[429]:


if yhat < 0.5: 
    print(f'Predicted class is dress.')
else:
    print(f'Predicted class is hat.')


# In[ ]:
