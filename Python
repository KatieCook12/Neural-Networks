# Installs dependencies
import tensorflow as tf
import os
import sys
# Removes incompatible images 
# Imports dependencies
import cv2
import imghdr

# Creates a variable holding the path to the data directory
data_dir = 'data'

# Creates a list of extensions 
image_exts = ['jpeg', 'jpg', 'bmp', 'png']
# Loops through every folder in the data directory
for subdir in ['test', 'train', 'validation']:
    for image_class in os.listdir(os.path.join(data_dir, subdir)):
        # Excludes the .DS_Store file
        if image_class == '.DS_Store':
            continue
        # Prints every single image within the sub-directory
        for image in os.listdir(os.path.join(data_dir, subdir, image_class)):
            # Grabs every image
            image_path = os.path.join(data_dir, subdir, image_class, image)
            try:
                # Opens an image using OpenCV
                img = cv2.imread(image_path)
                # Checks if the image is valid
                if imghdr.what(image_path) not in image_exts:
                    # Removes the image if it's not valid
                    os.remove(image_path)
                    print('Image not in exts list: {}'.format(image_path))
            except:
                # Removes the image if it cannot be opened
                os.remove(image_path)
                print('Issue with image: {}'.format(image_path))
# Imports dependencies
import numpy as np 
from matplotlib import pyplot as plt
# Builds an image dataset, using keras
test = tf.keras.utils.image_dataset_from_directory('data/test')
train = tf.keras.utils.image_dataset_from_directory('data/train')
val= tf.keras.utils.image_dataset_from_directory('data/validation')
Found 249 files belonging to 10 classes.
Found 3054 files belonging to 10 classes.
Found 194 files belonging to 10 classes.
# Allow us to convert to a numpy iterator, allows access to the image dataset
data_iterator_test = test.as_numpy_iterator()
data_iterator_train = train.as_numpy_iterator()
data_iterator_val = val.as_numpy_iterator()
# Grabs a batch 
try:
    batch_test = data_iterator_test.next()
    batch_train = data_iterator_train.next()
    batch_val = data_iterator_val.next()
except StopIteration:
    print("End of dataset reached")
# Checks which class is assigned to which image within the train dataset
fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch_train[0][:4]):
    ax[idx].imshow(img.astype(int))
    ax[idx].title.set_text(batch_train[1][idx])

# Scales the data
# x represents the images 
# y represents the labels
num_classes = 10  

test = test.map(lambda x, y: (x / 255, tf.one_hot(y, num_classes)))
train = train.map(lambda x, y: (x / 255, tf.one_hot(y, num_classes)))
val = val.map(lambda x, y: (x / 255, tf.one_hot(y, num_classes)))
# Iterates batches of data as NumPy arrays
# Every iterator returns a single data batch
scaled_iterator_test = test.as_numpy_iterator()
scaled_iterator_train = train.as_numpy_iterator()
scaled_iterator_val = val.as_numpy_iterator() 
# Scaled iterator
try: 
    batch_test = scaled_iterator_test.next()
    batch_train = scaled_iterator_train.next()
    batch_val = scaled_iterator_val.next()
except StopIteration:
    print("End of dataset reached")
# Grabs next batch
batch_test[0].max()
1.0
# Checks which class is assigned to which image within the test dataset
# Checks that they've been scaled correctly 
fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch_test[0][:4]):
    ax[idx].imshow(img)
    ax[idx].title.set_text(batch_test[1][idx])

# Grabs next batch
batch_train[0].max()
1.0
# Checks which class is assigned to which image
# Checks that they've been scaled correctly 
fig, ax = plt.subplots(ncols=1, figsize=(20,20))
for idx, img in enumerate(batch_train[0][:10]):
    ax[idx].imshow(img)
    ax[idx].title.set_text(batch_train[1][idx])
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In[30], line 5
      3 fig, ax = plt.subplots(ncols=1, figsize=(20,20))
      4 for idx, img in enumerate(batch_train[0][:10]):
----> 5     ax[idx].imshow(img)
      6     ax[idx].title.set_text(batch_train[1][idx])

TypeError: 'AxesSubplot' object is not subscriptable

# Grabs next batch
batch_val[0].max()
1.0
# Checks which class is assigned to which image
# Checks that they've been scaled correctly 
fig, ax = plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch_val[0][:4]):
    ax[idx].imshow(img)
    ax[idx].title.set_text(batch_val[1][idx])

# Imports dependencies
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
# Establishes an instance of the sequential class
model = Sequential()
# Adds in our layers

# Adds a convolutional layer and a max pooling layer
# Has 16 filters (3,3 pixels in size)
# Stride moving one pixel by one 
# Extracts the relevant information to make a classification
# Applies a relu activation - taking into account non-linear patterns
# Image shape is going to be 256 wide by 256 heigh, 3 channels deeps 
model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))
model.add(MaxPooling2D())

# Adds a convolutional layer and a max pooling layer
# Has 32 filters (3,3 pixels in size)
# Stride moving one pixel by one 
model.add(Conv2D(32, (3,3), 1, activation='relu'))
model.add(MaxPooling2D())

# Adds a convolutional layer and a max pooling layer
# Has 16 filters (3,3 pixels in size)
# Stride moving one pixel by one 
model.add(Conv2D(16, (3,3), 1, activation='softmax'))
model.add(MaxPooling2D())

# Flattens to remove the channels value 
model.add(Flatten())

# 256 values will now be the output
model.add(Dense(256, activation='relu'))
# Creates a single output, 0 or 1 
model.add(Dense(10, activation='relu'))
# Compiles the model using the 'adam' optimiser. Specifying what the loss is. The metric tracked is accuracy, shows how well the model is classifying either 0 or 1.
model.compile('adam', loss=tf.losses.CategoricalCrossentropy(), metrics=['accuracy'])
# Displays how the model transforms the data
model.summary()
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 254, 254, 16)      448       
                                                                 
 max_pooling2d (MaxPooling2D  (None, 127, 127, 16)     0         
 )                                                               
                                                                 
 conv2d_1 (Conv2D)           (None, 125, 125, 32)      4640      
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 62, 62, 32)       0         
 2D)                                                             
                                                                 
 conv2d_2 (Conv2D)           (None, 60, 60, 16)        4624      
                                                                 
 max_pooling2d_2 (MaxPooling  (None, 30, 30, 16)       0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 14400)             0         
                                                                 
 dense (Dense)               (None, 256)               3686656   
                                                                 
 dense_1 (Dense)             (None, 10)                2570      
                                                                 
=================================================================
Total params: 3,698,938
Trainable params: 3,698,938
Non-trainable params: 0
_________________________________________________________________
# Refers to the logs directory
logdir='logs'
# Logs model training into the 'logs' file
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)
# Model.fit takes in the training data
# Epoche is how long we're going to train for
# Passes through the validation data, to see how well the model is performing in real time
# Stores in a variable called history 
hist = model.fit(train, epochs=5, validation_data=val, callbacks=[tensorboard_callback])
Epoch 1/5
96/96 [==============================] - 104s 1s/step - loss: 2.8595 - accuracy: 0.2927 - val_loss: 3.1474 - val_accuracy: 0.3557
Epoch 2/5
96/96 [==============================] - 107s 1s/step - loss: 2.8590 - accuracy: 0.3127 - val_loss: 3.1983 - val_accuracy: 0.3608
Epoch 3/5
96/96 [==============================] - 97s 1s/step - loss: 2.8583 - accuracy: 0.3304 - val_loss: 3.1364 - val_accuracy: 0.3711
Epoch 4/5
93/96 [============================>.] - ETA: 3s - loss: 2.7840 - accuracy: 0.3545
# Plots the performance 
fig = plt.figure()

# Grabs the training loss
plt.plot(hist.history['loss'], color='teal', label='loss')

# Grabs the validation loss
plt.plot(hist.history['val_loss'], color='orange', label='val_loss')

fig.suptitle('Loss', fontsize=20)
plt.legend(loc="upper left")
plt.show()
# Plots the performance, visualising accuracy
fig = plt.figure()

plt.plot(hist.history['accuracy'], color='teal', label='accuracy')

plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')
fig.suptitle('Accuracy', fontsize=20)
plt.legend(loc="upper left")
plt.show()
# Imports key metrics
from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy
# Establishes instances of the metrics
pre = Precision()
re = Recall()
acc = BinaryAccuracy()
# Loops through each batch in the testing data
for batch in test.as_numpy_iterator(): 
    X, y = batch
    # Passes image data to our model, returns values of 0 or 1 
    yhat = model.predict(X)
    # Returns precision
    pre.update_state(y, yhat)
    # Returns recall
    re.update_state(y, yhat)
    # Returns accuracy
    acc.update_state(y, yhat)
print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy: {acc.result().numpy()}')
# Imports opencv
import cv2
# Reads and display images
img = cv2.imread('5a2b4bbf-d9fe-45a2-aa0d-295a86804cb6.jpg')
plt.imshow(img)
plt.show()
# Resizes to 256 wide and 256 heigh
resize = tf.image.resize(img, (256,256))
# Displays the resized image
plt.imshow(resize.numpy().astype(int))
plt.show()
yhat = model.predict(np.expand_dims(resize/255, 0))
yhat
if yhat < 0.5: 
    print(f'Predicted class is dress.')
else:
    print(f'Predicted class is hat.')
 
